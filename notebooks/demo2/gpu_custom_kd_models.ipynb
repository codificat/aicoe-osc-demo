{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee11b421",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference with teacher-student Models \n",
    "\n",
    "Custom knowledge distillation is a popular technique in deep learning, which involves training a smaller, simpler model (the \"student\") to mimic the behavior of a larger, more complex model (the \"teacher\"). This technique is aimed at improving the efficiency of deep learning models by compressing the knowledge of the larger model into a smaller one, without sacrificing too much accuracy.\n",
    "\n",
    "In this notebook, we will be investigating the inference time of custom knowledge distillation models using GPU acceleration with PyTorch. Specifically, we will be focusing on three pre-trained models: '12layer_pruned80-none', '12layer_pruned90-none', and 'teacher'. Our objective is to calculate the inference time of these models and evaluate the impact of the GPU on their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1eb0c2",
   "metadata": {
    "papermill": {
     "duration": 3.30074,
     "end_time": "2022-10-07T19:33:18.885511",
     "exception": false,
     "start_time": "2022-10-07T19:33:15.584771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from src.data.s3_communication import S3Communication, S3FileType\n",
    "from src.components.utils.kpi_mapping import get_kpi_mapping_category\n",
    "import json\n",
    "import time\n",
    "import config\n",
    "from transformers import AutoTokenizer\n",
    "import random\n",
    "from torch import cuda\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad4b2028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv_dir = os.environ.get(\n",
    "    \"CREDENTIAL_DOTENV_DIR\", os.environ.get(\"PWD\", \"/opt/app-root/src\")\n",
    ")\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / \"credentials.env\"\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d61eb734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init s3 connector\n",
    "s3c = S3Communication(\n",
    "    s3_endpoint_url=os.getenv(\"S3_ENDPOINT\"),\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    s3_bucket=os.getenv(\"S3_BUCKET\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd72537",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55e007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(data_df, batch_size=32):\n",
    "    encoded_dataset = list()\n",
    "    batch = list()\n",
    "    for df, row in data_df.iterrows():\n",
    "        if len(batch) < batch_size:\n",
    "            batch.append([row['question'], row['sentence']])\n",
    "        else:\n",
    "            encoded_dataset.append(tokenizer(batch,\n",
    "                                             truncation=True,\n",
    "                                             return_tensors='pt',\n",
    "                                             padding=True))\n",
    "            batch = [[row['question'], row['sentence']]]\n",
    "    if batch:\n",
    "        encoded_dataset.append(tokenizer(batch,\n",
    "                                         truncation=True,\n",
    "                                         return_tensors='pt',\n",
    "                                         padding=True))\n",
    "    return encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da4b1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(pdf_name, pdf_path):\n",
    "    pdf_content = read_text_from_json(file_path)\n",
    "    text_data = []\n",
    "    # Build all possible combinations of paragraphs and  questions\n",
    "    # Keep track of page number which the text is extracted from and\n",
    "    # the pdf it belongs to.\n",
    "    for kpi_question in questions:\n",
    "        text_data.extend([{\n",
    "            \"page\": page_num,\n",
    "            \"pdf_name\": pdf_name,\n",
    "            \"question\": kpi_question,\n",
    "            \"sentence\": paragraph}\n",
    "            for page_num, page_content in pdf_content.items()\n",
    "            for paragraph in page_content])\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e447928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(encoded_dataset):\n",
    "    outputs = list()\n",
    "    for batch in encoded_dataset:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            outputs.extend(outs.logits.argmax(axis=1).tolist())\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ce22e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_from_json(file):\n",
    "    \"\"\"Read text from json.\"\"\"\n",
    "\n",
    "    with open(file) as f:\n",
    "        text = json.load(f)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db64acf",
   "metadata": {},
   "source": [
    "## Retrieve the test dataset and the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a79818",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3c.download_files_in_prefix_to_dir(\n",
    "    config.BASE_TRAIN_TEST_DATASET_S3_PREFIX,\n",
    "    config.BASE_PROCESSED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "829a635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = str(config.BASE_PROCESSED_DATA)+'/rel_test_split.csv'\n",
    "test_data = pd.read_csv(test_data_path, index_col=0)\n",
    "test_data.rename(columns={'text': 'question', 'text_b':'sentence'}, inplace=True)\n",
    "\n",
    "train_data_path = str(config.BASE_PROCESSED_DATA)+'/rel_train_split.csv'\n",
    "train_data = pd.read_csv(train_data_path, index_col=0)\n",
    "train_data.rename(columns={'text': 'question', 'text_b':'sentence'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32210f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "trds = Dataset.from_pandas(train_data)\n",
    "teds = Dataset.from_pandas(test_data.drop('label', axis=1))\n",
    "\n",
    "climate_dataset = DatasetDict()\n",
    "\n",
    "climate_dataset['train'] = trds\n",
    "climate_dataset['test'] = teds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "790cd0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'question', 'sentence', '__index_level_0__'],\n",
       "        num_rows: 2033\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'sentence', '__index_level_0__'],\n",
       "        num_rows: 509\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f3622",
   "metadata": {},
   "source": [
    "PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddcfeddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/opt/app-root/src/data')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97cea1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARK_FOLDER = config.DATA_FOLDER\n",
    "if not os.path.exists(BENCHMARK_FOLDER):\n",
    "    BENCHMARK_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BENCHMARK_EXTRACTION_FOLDER = BENCHMARK_FOLDER / \"extraction\"\n",
    "if not os.path.exists(BENCHMARK_EXTRACTION_FOLDER):\n",
    "    pathlib.Path(BENCHMARK_EXTRACTION_FOLDER).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "517064c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_df = s3c.download_df_from_s3(\n",
    "    \"aicoe-osc-demo/kpi_mapping\",\n",
    "    \"kpi_mapping.csv\",\n",
    "    filetype=S3FileType.CSV,\n",
    "    header=0)\n",
    "\n",
    "kmc = get_kpi_mapping_category(kpi_df)\n",
    "questions = [q_text for q_id, (q_text, sect) in kmc[\"KPI_MAPPING_MODEL\"].items()\n",
    "             if len(set(sect).intersection({\"OG\", \"CM\", \"CU\"})) > 0\n",
    "             and \"TEXT\" in kmc[\"KPI_CATEGORY\"][q_id]]\n",
    "\n",
    "text_paths = sorted(BENCHMARK_EXTRACTION_FOLDER.rglob(\"*.json\"))\n",
    "all_text_path_dict = {os.path.splitext(os.path.basename(file_path))[0]:\n",
    "                      file_path for file_path in text_paths\n",
    "                      if \"table_meta\" not in str(file_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af60178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing 10 random pdfs\n",
    "all_text_path_dict = dict(random.sample(all_text_path_dict.items(), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc426109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "metrics_df_list = []\n",
    "metrics_list = []\n",
    "metric_dfs = pd.DataFrame()\n",
    "num_pdfs = len(all_text_path_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79a6659f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LUKOIL_SUSTAINABILITY_REPORT_2018': PosixPath('/opt/app-root/src/data/extraction/LUKOIL_SUSTAINABILITY_REPORT_2018.json'),\n",
       " 'equinor-2019-annual-report-and-form-20f': PosixPath('/opt/app-root/src/data/extraction/equinor-2019-annual-report-and-form-20f.json'),\n",
       " '413750375_Avista Corp_2019-12-31': PosixPath('/opt/app-root/src/data/extraction/413750375_Avista Corp_2019-12-31.json'),\n",
       " '2018 Annual Report': PosixPath('/opt/app-root/src/data/extraction/2018 Annual Report.json'),\n",
       " 'Ervia-Annual-Report-2018': PosixPath('/opt/app-root/src/data/extraction/Ervia-Annual-Report-2018.json'),\n",
       " 'SaipemSustainability2018': PosixPath('/opt/app-root/src/data/extraction/SaipemSustainability2018.json'),\n",
       " 'RN_SR_2016_EN_2_ sustainabilitz 2016': PosixPath('/opt/app-root/src/data/extraction/RN_SR_2016_EN_2_ sustainabilitz 2016.json'),\n",
       " 'Eskom Holdings SOC Ltd Integrated Report 2019': PosixPath('/opt/app-root/src/data/extraction/Eskom Holdings SOC Ltd Integrated Report 2019.json'),\n",
       " 'Sustainability Report 2016_EN': PosixPath('/opt/app-root/src/data/extraction/Sustainability Report 2016_EN.json'),\n",
       " 'annual_report_2019_eng': PosixPath('/opt/app-root/src/data/extraction/annual_report_2019_eng.json')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca32a7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(num_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd32ffe5-cd92-498f-b27d-d8b5f8353504",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_paths=['models/12layer_pruned80-none/',\n",
    "                   'models/12layer_pruned90-none/',\n",
    "                   'models/teacher/']\n",
    "\n",
    "model_names=['12layer_pruned80-none',\n",
    "             '12layer_pruned90-none',\n",
    "             'teacher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f53ad175-e12a-4cff-ab5a-64e835db28a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_paths=['models/teacher/']\n",
    "\n",
    "model_names = ['teacher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "118ac1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop : 0\n",
      "Processing 1/10, LUKOIL_SUSTAINABILITY_REPORT_2018\n",
      "loop : 1\n",
      "Processing 2/10, equinor-2019-annual-report-and-form-20f\n",
      "loop : 2\n",
      "Processing 3/10, 413750375_Avista Corp_2019-12-31\n",
      "loop : 3\n",
      "Processing 4/10, 2018 Annual Report\n",
      "loop : 4\n",
      "Processing 5/10, Ervia-Annual-Report-2018\n",
      "loop : 5\n",
      "Processing 6/10, SaipemSustainability2018\n",
      "loop : 6\n",
      "Processing 7/10, RN_SR_2016_EN_2_ sustainabilitz 2016\n",
      "loop : 7\n",
      "Processing 8/10, Eskom Holdings SOC Ltd Integrated Report 2019\n",
      "loop : 8\n",
      "Processing 9/10, Sustainability Report 2016_EN\n",
      "loop : 9\n",
      "Processing 10/10, annual_report_2019_eng\n"
     ]
    }
   ],
   "source": [
    "metric_list = []\n",
    "for local_model_path, model_name in zip(local_model_paths,model_names):\n",
    "    for i, (pdf_name,file_path) in enumerate(all_text_path_dict.items()):\n",
    "        print(f\"loop : {i}\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(local_model_path, use_fast=True)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(local_model_path).to(device)\n",
    "        encoded_dataset = create_batches(test_data)\n",
    "\n",
    "        print(f'Processing {i+1}/{len(all_text_path_dict)}, {pdf_name}')\n",
    "        data = gather_data(pdf_name, file_path)\n",
    "        num_data_points = len(data)\n",
    "        num_pages = data[len(data)-1]['page']\n",
    "        chunk_size = 1000\n",
    "        chunk_idx = 0\n",
    "        total_file_time = 0\n",
    "\n",
    "        predictions = list()\n",
    "        while chunk_idx * chunk_size < num_data_points:\n",
    "            chunk_start = time.time()\n",
    "            data_chunk = data[chunk_idx * chunk_size:(chunk_idx + 1) * chunk_size]\n",
    "            temp_df = pd.DataFrame(data_chunk).drop(['pdf_name', 'page'], axis=1)\n",
    "            encoded_dataset = create_batches(temp_df, batch_size=128)\n",
    "            predictions.extend(predict(encoded_dataset))\n",
    "            chunk_idx += 1\n",
    "            chunk_end = time.time()\n",
    "            total_file_time += (chunk_end - chunk_start)\n",
    "\n",
    "        time_per_data_point = total_file_time / num_data_points\n",
    "        data_points_per_sec = 1/time_per_data_point\n",
    "        model_size = os.path.getsize(local_model_path + 'pytorch_model.bin')/1000000\n",
    "\n",
    "        metric_list.append(\n",
    "            {'Model Name':model_name,\n",
    "             'Model Size(MB)': model_size,\n",
    "             'PDF Name':pdf_name,\n",
    "             'Number of Pages':int(num_pages),\n",
    "             'Number of Data Points':num_data_points,\n",
    "             'Total Inference Time':total_file_time,\n",
    "             'Time per data point':time_per_data_point,\n",
    "             'Data points per sec':data_points_per_sec})\n",
    "\n",
    "    file_to_save = pd.DataFrame(metric_list)\n",
    "    file_to_save.to_csv(f\"file_to_save_{model_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26b575aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dfs = pd.DataFrame(metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39993a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Size(MB)</th>\n",
       "      <th>PDF Name</th>\n",
       "      <th>Number of Pages</th>\n",
       "      <th>Number of Data Points</th>\n",
       "      <th>Total Inference Time</th>\n",
       "      <th>Time per data point</th>\n",
       "      <th>Data points per sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teacher</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>LUKOIL_SUSTAINABILITY_REPORT_2018</td>\n",
       "      <td>81</td>\n",
       "      <td>52392</td>\n",
       "      <td>201.269272</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>260.307992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teacher</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>equinor-2019-annual-report-and-form-20f</td>\n",
       "      <td>317</td>\n",
       "      <td>82368</td>\n",
       "      <td>489.522515</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>168.261924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teacher</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>413750375_Avista Corp_2019-12-31</td>\n",
       "      <td>79</td>\n",
       "      <td>81072</td>\n",
       "      <td>108.448538</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>747.561948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teacher</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>2018 Annual Report</td>\n",
       "      <td>147</td>\n",
       "      <td>34152</td>\n",
       "      <td>205.439296</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>166.238887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teacher</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>Ervia-Annual-Report-2018</td>\n",
       "      <td>155</td>\n",
       "      <td>41232</td>\n",
       "      <td>151.551620</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>272.065717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name  Model Size(MB)                                 PDF Name  \\\n",
       "0    teacher      438.011337        LUKOIL_SUSTAINABILITY_REPORT_2018   \n",
       "1    teacher      438.011337  equinor-2019-annual-report-and-form-20f   \n",
       "2    teacher      438.011337         413750375_Avista Corp_2019-12-31   \n",
       "3    teacher      438.011337                       2018 Annual Report   \n",
       "4    teacher      438.011337                 Ervia-Annual-Report-2018   \n",
       "\n",
       "   Number of Pages  Number of Data Points  Total Inference Time  \\\n",
       "0               81                  52392            201.269272   \n",
       "1              317                  82368            489.522515   \n",
       "2               79                  81072            108.448538   \n",
       "3              147                  34152            205.439296   \n",
       "4              155                  41232            151.551620   \n",
       "\n",
       "   Time per data point  Data points per sec  \n",
       "0             0.003842           260.307992  \n",
       "1             0.005943           168.261924  \n",
       "2             0.001338           747.561948  \n",
       "3             0.006015           166.238887  \n",
       "4             0.003676           272.065717  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_dfs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c040c",
   "metadata": {},
   "source": [
    "**Model Name: 12layer_pruned80-none, Size: 438.02 MB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23de10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"file_to_save_12layer_pruned90-none.csv\")\n",
    "df1 = df[df['Model Name']=='12layer_pruned80-none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5afefd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Size(MB)</th>\n",
       "      <th>PDF Name</th>\n",
       "      <th>Number of Pages</th>\n",
       "      <th>Number of Data Points</th>\n",
       "      <th>Total Inference Time</th>\n",
       "      <th>Time per data point</th>\n",
       "      <th>Data points per sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12layer_pruned80-none</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>04_NOVATEK_AR_2016_ENG_11</td>\n",
       "      <td>119</td>\n",
       "      <td>24264</td>\n",
       "      <td>115.039156</td>\n",
       "      <td>0.004741</td>\n",
       "      <td>210.919490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12layer_pruned80-none</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>04_NOVATEK_AR_2018_ENG_15</td>\n",
       "      <td>105</td>\n",
       "      <td>23112</td>\n",
       "      <td>106.168256</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>217.692189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12layer_pruned80-none</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>2013_book_mol_ar_eng_fin</td>\n",
       "      <td>135</td>\n",
       "      <td>63024</td>\n",
       "      <td>377.481622</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>166.959122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12layer_pruned80-none</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>2015_BASF_Report</td>\n",
       "      <td>261</td>\n",
       "      <td>76392</td>\n",
       "      <td>482.745011</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>158.245033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12layer_pruned80-none</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>2017 Sustainability Report</td>\n",
       "      <td>57</td>\n",
       "      <td>21936</td>\n",
       "      <td>64.461510</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>340.296093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             Model Name  Model Size(MB)  \\\n",
       "0           0  12layer_pruned80-none      438.011337   \n",
       "1           1  12layer_pruned80-none      438.011337   \n",
       "2           2  12layer_pruned80-none      438.011337   \n",
       "3           3  12layer_pruned80-none      438.011337   \n",
       "4           4  12layer_pruned80-none      438.011337   \n",
       "\n",
       "                     PDF Name  Number of Pages  Number of Data Points  \\\n",
       "0   04_NOVATEK_AR_2016_ENG_11              119                  24264   \n",
       "1   04_NOVATEK_AR_2018_ENG_15              105                  23112   \n",
       "2    2013_book_mol_ar_eng_fin              135                  63024   \n",
       "3            2015_BASF_Report              261                  76392   \n",
       "4  2017 Sustainability Report               57                  21936   \n",
       "\n",
       "   Total Inference Time  Time per data point  Data points per sec  \n",
       "0            115.039156             0.004741           210.919490  \n",
       "1            106.168256             0.004594           217.692189  \n",
       "2            377.481622             0.005989           166.959122  \n",
       "3            482.745011             0.006319           158.245033  \n",
       "4             64.461510             0.002939           340.296093  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30bc1762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    153.000000\n",
       "mean       0.004110\n",
       "std        0.001773\n",
       "min        0.000887\n",
       "25%        0.003060\n",
       "50%        0.003964\n",
       "75%        0.004961\n",
       "max        0.009390\n",
       "Name: Time per data point, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average time per data point\n",
    "\n",
    "df1['Time per data point'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb5cb01",
   "metadata": {},
   "source": [
    "The average time per data point is 0.004110 seconds. A pdf with on average ~151 pages, and ~ 312 data points per page, will take ~3.2 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db31b48",
   "metadata": {},
   "source": [
    "**Model Name: 12layer_pruned90-none, Size: 438.02 MB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af40449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['Model Name']=='12layer_pruned90-none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d05084d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Size(MB)</th>\n",
       "      <th>PDF Name</th>\n",
       "      <th>Number of Pages</th>\n",
       "      <th>Number of Data Points</th>\n",
       "      <th>Total Inference Time</th>\n",
       "      <th>Time per data point</th>\n",
       "      <th>Data points per sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>12layer_pruned90-none</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>04_NOVATEK_AR_2016_ENG_11</td>\n",
       "      <td>119</td>\n",
       "      <td>24264</td>\n",
       "      <td>116.594925</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>208.105112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>154</td>\n",
       "      <td>12layer_pruned90-none</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>04_NOVATEK_AR_2018_ENG_15</td>\n",
       "      <td>105</td>\n",
       "      <td>23112</td>\n",
       "      <td>106.076298</td>\n",
       "      <td>0.004590</td>\n",
       "      <td>217.880906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>155</td>\n",
       "      <td>12layer_pruned90-none</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>2013_book_mol_ar_eng_fin</td>\n",
       "      <td>135</td>\n",
       "      <td>63024</td>\n",
       "      <td>375.350579</td>\n",
       "      <td>0.005956</td>\n",
       "      <td>167.907028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>156</td>\n",
       "      <td>12layer_pruned90-none</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>2015_BASF_Report</td>\n",
       "      <td>261</td>\n",
       "      <td>76392</td>\n",
       "      <td>479.766905</td>\n",
       "      <td>0.006280</td>\n",
       "      <td>159.227323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>157</td>\n",
       "      <td>12layer_pruned90-none</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>2017 Sustainability Report</td>\n",
       "      <td>57</td>\n",
       "      <td>21936</td>\n",
       "      <td>63.929079</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>343.130235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0             Model Name  Model Size(MB)  \\\n",
       "153         153  12layer_pruned90-none      438.011337   \n",
       "154         154  12layer_pruned90-none      438.011337   \n",
       "155         155  12layer_pruned90-none      438.011337   \n",
       "156         156  12layer_pruned90-none      438.011337   \n",
       "157         157  12layer_pruned90-none      438.011337   \n",
       "\n",
       "                       PDF Name  Number of Pages  Number of Data Points  \\\n",
       "153   04_NOVATEK_AR_2016_ENG_11              119                  24264   \n",
       "154   04_NOVATEK_AR_2018_ENG_15              105                  23112   \n",
       "155    2013_book_mol_ar_eng_fin              135                  63024   \n",
       "156            2015_BASF_Report              261                  76392   \n",
       "157  2017 Sustainability Report               57                  21936   \n",
       "\n",
       "     Total Inference Time  Time per data point  Data points per sec  \n",
       "153            116.594925             0.004805           208.105112  \n",
       "154            106.076298             0.004590           217.880906  \n",
       "155            375.350579             0.005956           167.907028  \n",
       "156            479.766905             0.006280           159.227323  \n",
       "157             63.929079             0.002914           343.130235  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab66e155-3e58-42e2-a47f-6c54e37cc3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    153.000000\n",
       "mean       0.004088\n",
       "std        0.001764\n",
       "min        0.000882\n",
       "25%        0.003055\n",
       "50%        0.003934\n",
       "75%        0.004939\n",
       "max        0.009329\n",
       "Name: Time per data point, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average time per data point\n",
    "\n",
    "df2['Time per data point'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c67f34",
   "metadata": {},
   "source": [
    "The average time per data point is 0.004088 seconds. A pdf with on average ~151 pages, and ~312 data points per page, will take ~3.2 mins to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7482cd7a-b857-4918-be92-6cc6b2a961df",
   "metadata": {},
   "source": [
    "**Model_Name : teacher**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "266edaa7-9de5-4ca6-bb46-2ec400d0d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"file_to_save_teacher.csv\")\n",
    "df3 = df[df['Model Name']=='teacher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bdf7460-22d9-4ca4-8be6-010274c55e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Size(MB)</th>\n",
       "      <th>PDF Name</th>\n",
       "      <th>Number of Pages</th>\n",
       "      <th>Number of Data Points</th>\n",
       "      <th>Total Inference Time</th>\n",
       "      <th>Time per data point</th>\n",
       "      <th>Data points per sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>teacher</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>LUKOIL_SUSTAINABILITY_REPORT_2018</td>\n",
       "      <td>81</td>\n",
       "      <td>52392</td>\n",
       "      <td>201.269272</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>260.307992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>teacher</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>equinor-2019-annual-report-and-form-20f</td>\n",
       "      <td>317</td>\n",
       "      <td>82368</td>\n",
       "      <td>489.522515</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>168.261924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>teacher</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>413750375_Avista Corp_2019-12-31</td>\n",
       "      <td>79</td>\n",
       "      <td>81072</td>\n",
       "      <td>108.448538</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>747.561948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>teacher</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>2018 Annual Report</td>\n",
       "      <td>147</td>\n",
       "      <td>34152</td>\n",
       "      <td>205.439296</td>\n",
       "      <td>0.006015</td>\n",
       "      <td>166.238887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>teacher</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>Ervia-Annual-Report-2018</td>\n",
       "      <td>155</td>\n",
       "      <td>41232</td>\n",
       "      <td>151.551620</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>272.065717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Model Name  Model Size(MB)  \\\n",
       "0           0    teacher      438.011337   \n",
       "1           1    teacher      438.011337   \n",
       "2           2    teacher      438.011337   \n",
       "3           3    teacher      438.011337   \n",
       "4           4    teacher      438.011337   \n",
       "\n",
       "                                  PDF Name  Number of Pages  \\\n",
       "0        LUKOIL_SUSTAINABILITY_REPORT_2018               81   \n",
       "1  equinor-2019-annual-report-and-form-20f              317   \n",
       "2         413750375_Avista Corp_2019-12-31               79   \n",
       "3                       2018 Annual Report              147   \n",
       "4                 Ervia-Annual-Report-2018              155   \n",
       "\n",
       "   Number of Data Points  Total Inference Time  Time per data point  \\\n",
       "0                  52392            201.269272             0.003842   \n",
       "1                  82368            489.522515             0.005943   \n",
       "2                  81072            108.448538             0.001338   \n",
       "3                  34152            205.439296             0.006015   \n",
       "4                  41232            151.551620             0.003676   \n",
       "\n",
       "   Data points per sec  \n",
       "0           260.307992  \n",
       "1           168.261924  \n",
       "2           747.561948  \n",
       "3           166.238887  \n",
       "4           272.065717  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f476eb81-b588-4fa6-9cab-942eb4003ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10.000000\n",
       "mean      0.004445\n",
       "std       0.002242\n",
       "min       0.001338\n",
       "25%       0.003455\n",
       "50%       0.003757\n",
       "75%       0.005418\n",
       "max       0.009573\n",
       "Name: Time per data point, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average time per data point\n",
    "\n",
    "df3['Time per data point'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef418dda-ca3f-44bf-b517-e7ead381a130",
   "metadata": {},
   "source": [
    "The average time per data point is 0.004445 seconds. A pdf with on average ~151 pages, and ~312 data points per page, will take ~3.4 mins to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f31cfdb",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1579e0a8",
   "metadata": {},
   "source": [
    "Here we create a conclusive table which contains the information about different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec57937c-d959-4131-800e-07b9ff7b173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = 'zoo:nlp/masked_language_modeling/bert-base/pytorch/' \\\n",
    "         'huggingface/bookcorpus_wikitext/12layer_pruned90-none?' \\\n",
    "         'recipe_type=transfer-MNLI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f47d04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table={'model_name':['12layer_pruned90-none',\n",
    "                           '12layer_pruned80-none',\n",
    "                           'teacher'],\n",
    "             'Recipe_used':[recipe,\n",
    "                            recipe,\n",
    "                            'N/A',],\n",
    "             'Size (MB)':[os.path.getsize('models/12layer_pruned90-none/pytorch_model.bin')/1000000,\n",
    "                          os.path.getsize('models/12layer_pruned80-none/pytorch_model.bin')/1000000,\n",
    "                          os.path.getsize('models/teacher/pytorch_model.bin')/1000000],\n",
    "             'inference_time_for_avg_pdf (mins)':[3.2, 3.2, 3.4],\n",
    "             'F1-Score':[86.50, 86.91, 91.24]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26a9ae28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>Recipe_used</th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>inference_time_for_avg_pdf (mins)</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12layer_pruned90-none</td>\n",
       "      <td>zoo:nlp/masked_language_modeling/bert-base/pyt...</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>3.2</td>\n",
       "      <td>86.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12layer_pruned80-none</td>\n",
       "      <td>zoo:nlp/masked_language_modeling/bert-base/pyt...</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>3.2</td>\n",
       "      <td>86.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teacher</td>\n",
       "      <td>N/A</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>3.4</td>\n",
       "      <td>91.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_name                                        Recipe_used  \\\n",
       "0  12layer_pruned90-none  zoo:nlp/masked_language_modeling/bert-base/pyt...   \n",
       "1  12layer_pruned80-none  zoo:nlp/masked_language_modeling/bert-base/pyt...   \n",
       "2                teacher                                                N/A   \n",
       "\n",
       "    Size (MB)  inference_time_for_avg_pdf (mins)  F1-Score  \n",
       "0  438.011337                                3.2     86.50  \n",
       "1  438.011337                                3.2     86.91  \n",
       "2  438.011337                                3.4     91.24  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83fdfde-9042-4408-9fe6-b9f19ca286de",
   "metadata": {},
   "source": [
    "Based on our experimentation, we have evaluated the performance of three different models trained with custom knowledge distillation: '12layer_pruned90-none', '12layer_pruned80-none', and 'teacher'. These models were tested on GPU using PyTorch for calculating the inference time and F1 score. \n",
    "\n",
    "The knowledge distillation process has allowed us to train more efficient and smaller models, with comparable performance to the larger, more complex models. The use of GPU and PyTorch has also provided faster computation times for these models, facilitating their use in real-world applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
