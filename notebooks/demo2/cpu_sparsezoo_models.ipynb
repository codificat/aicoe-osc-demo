{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee11b421",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference test for SparseZoo Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e09cb02-0a4d-434f-87ad-a703a27dec6f",
   "metadata": {},
   "source": [
    "In this notebook, we are exploring the capabilities of SparseZoo and DeepSparse by using pre-trained models from SparseZoo and performing inference tests using DeepSparse, but only on the CPU. By limiting our experiments to the CPU, we can gain insights into how efficiently these frameworks can optimize sparse models for execution on general-purpose hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1eb0c2",
   "metadata": {
    "papermill": {
     "duration": 3.30074,
     "end_time": "2022-10-07T19:33:18.885511",
     "exception": false,
     "start_time": "2022-10-07T19:33:15.584771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "from src.data.s3_communication import S3Communication, S3FileType\n",
    "from src.components.utils.kpi_mapping import get_kpi_mapping_category\n",
    "import json\n",
    "import time\n",
    "import config\n",
    "from torch import cuda\n",
    "from deepsparse import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4b2028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv_dir = os.environ.get(\n",
    "    \"CREDENTIAL_DOTENV_DIR\", os.environ.get(\"PWD\", \"/opt/app-root/src\")\n",
    ")\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / \"credentials.env\"\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61eb734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init s3 connector\n",
    "s3c = S3Communication(\n",
    "    s3_endpoint_url=os.getenv(\"S3_ENDPOINT\"),\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    s3_bucket=os.getenv(\"S3_BUCKET\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd72537",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4b1a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(pdf_name, pdf_path):\n",
    "    pdf_content = read_text_from_json(file_path)\n",
    "    text_data = []\n",
    "    # Build all possible combinations of paragraphs and  questions\n",
    "    # Keep track of page number which the text is extracted from and\n",
    "    # the pdf it belongs to.\n",
    "    for kpi_question in questions:\n",
    "        text_data.extend([{\n",
    "            \"page\": page_num,\n",
    "            \"pdf_name\": pdf_name,\n",
    "            \"question\": kpi_question,\n",
    "            \"sentence\": paragraph}\n",
    "            for page_num, page_content in pdf_content.items()\n",
    "            for paragraph in page_content])\n",
    "    return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46ce22e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_from_json(file):\n",
    "    \"\"\"Read text from json.\"\"\"\n",
    "\n",
    "    with open(file) as f:\n",
    "        text = json.load(f)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db64acf",
   "metadata": {},
   "source": [
    "## Retrieve the test dataset and the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a79818",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3c.download_files_in_prefix_to_dir(\n",
    "    config.BASE_TRAIN_TEST_DATASET_S3_PREFIX,\n",
    "    config.BASE_PROCESSED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "829a635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = str(config.BASE_PROCESSED_DATA)+'/rel_test_split.csv'\n",
    "test_data = pd.read_csv(test_data_path, index_col=0)\n",
    "test_data.rename(columns={'text': 'question', 'text_b':'sentence'}, inplace=True)\n",
    "\n",
    "train_data_path = str(config.BASE_PROCESSED_DATA)+'/rel_train_split.csv'\n",
    "train_data = pd.read_csv(train_data_path, index_col=0)\n",
    "train_data.rename(columns={'text': 'question', 'text_b':'sentence'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32210f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "trds = Dataset.from_pandas(train_data)\n",
    "teds = Dataset.from_pandas(test_data.drop('label', axis=1))\n",
    "\n",
    "climate_dataset = DatasetDict()\n",
    "\n",
    "climate_dataset['train'] = trds\n",
    "climate_dataset['test'] = teds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "790cd0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'question', 'sentence', '__index_level_0__'],\n",
       "        num_rows: 2033\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'sentence', '__index_level_0__'],\n",
       "        num_rows: 509\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f3622",
   "metadata": {},
   "source": [
    "PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddcfeddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/opt/app-root/src/data')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97cea1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BENCHMARK_FOLDER = config.DATA_FOLDER\n",
    "if not os.path.exists(BENCHMARK_FOLDER):\n",
    "    BENCHMARK_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BENCHMARK_EXTRACTION_FOLDER = BENCHMARK_FOLDER / \"extraction\"\n",
    "if not os.path.exists(BENCHMARK_EXTRACTION_FOLDER):\n",
    "    pathlib.Path(BENCHMARK_EXTRACTION_FOLDER).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "517064c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi_df = s3c.download_df_from_s3(\n",
    "    \"aicoe-osc-demo/kpi_mapping\",\n",
    "    \"kpi_mapping.csv\",\n",
    "    filetype=S3FileType.CSV,\n",
    "    header=0)\n",
    "\n",
    "kmc = get_kpi_mapping_category(kpi_df)\n",
    "questions = [q_text for q_id, (q_text, sect) in kmc[\"KPI_MAPPING_MODEL\"].items()\n",
    "             if len(set(sect).intersection({\"OG\", \"CM\", \"CU\"})) > 0\n",
    "             and \"TEXT\" in kmc[\"KPI_CATEGORY\"][q_id]]\n",
    "\n",
    "text_paths = sorted(BENCHMARK_EXTRACTION_FOLDER.rglob(\"*.json\"))\n",
    "all_text_path_dict = {os.path.splitext(os.path.basename(file_path))[0]:\n",
    "                      file_path for file_path in text_paths\n",
    "                      if \"table_meta\" not in str(file_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af60178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing 5 pdfs\n",
    "all_text_path_dict = dict(list(all_text_path_dict.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c55f56b-672f-4ea6-9de9-6479623a3c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'04_NOVATEK_AR_2016_ENG_11': PosixPath('/opt/app-root/src/data/extraction/04_NOVATEK_AR_2016_ENG_11.json'),\n",
       " '04_NOVATEK_AR_2018_ENG_15': PosixPath('/opt/app-root/src/data/extraction/04_NOVATEK_AR_2018_ENG_15.json'),\n",
       " '2013_book_mol_ar_eng_fin': PosixPath('/opt/app-root/src/data/extraction/2013_book_mol_ar_eng_fin.json'),\n",
       " '2015_BASF_Report': PosixPath('/opt/app-root/src/data/extraction/2015_BASF_Report.json'),\n",
       " '2017 Sustainability Report': PosixPath('/opt/app-root/src/data/extraction/2017 Sustainability Report.json')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc426109",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "metrics_df_list = []\n",
    "metrics_list = []\n",
    "metric_dfs = pd.DataFrame()\n",
    "num_pdfs = len(all_text_path_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79a6659f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'04_NOVATEK_AR_2016_ENG_11': PosixPath('/opt/app-root/src/data/extraction/04_NOVATEK_AR_2016_ENG_11.json'),\n",
       " '04_NOVATEK_AR_2018_ENG_15': PosixPath('/opt/app-root/src/data/extraction/04_NOVATEK_AR_2018_ENG_15.json'),\n",
       " '2013_book_mol_ar_eng_fin': PosixPath('/opt/app-root/src/data/extraction/2013_book_mol_ar_eng_fin.json'),\n",
       " '2015_BASF_Report': PosixPath('/opt/app-root/src/data/extraction/2015_BASF_Report.json'),\n",
       " '2017 Sustainability Report': PosixPath('/opt/app-root/src/data/extraction/2017 Sustainability Report.json')}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca32a7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(num_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac807bde-c375-4244-9b9d-a2940ea96c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_paths=['/opt/app-root/src/aicoe-osc-demo/models/distilbert_mnli_pruned80/deployment/',\n",
    "                   '/opt/app-root/src/aicoe-osc-demo/models/distilbert_qqp_pruned80/deployment/',\n",
    "                   '/opt/app-root/src/aicoe-osc-demo/models/obert_mnli_pruned90/deployment/']\n",
    "\n",
    "model_names=['distilbert_mnli_pruned80','distilbert_qqp_pruned80','obert_mnli_pruned90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "118ac1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 07:41:14 deepsparse.transformers WARNING  sparseml-transformers v4.23.1 installation not detected. Installing  sparseml-transformers v4.23.1 dependencies if transformers is already  installed in the environment, it will be overwritten. Set  environment variable NM_NO_AUTOINSTALL_TRANSFORMERS to disable\n",
      "2023-01-13 07:41:14,255 [558] WARNING  deepsparse.transformers: sparseml-transformers v4.23.1 installation not detected. Installing  sparseml-transformers v4.23.1 dependencies if transformers is already  installed in the environment, it will be overwritten. Set  environment variable NM_NO_AUTOINSTALL_TRANSFORMERS to disable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.23.1\n",
      "  Downloading https://github.com/neuralmagic/transformers/releases/download/v1.3/transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 18.2 MB/s eta 0:00:00\n",
      "Collecting datasets<=1.18.4\n",
      "  Downloading datasets-1.18.4-py3-none-any.whl (312 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 312.1/312.1 kB 55.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sklearn in /opt/app-root/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: seqeval in /opt/app-root/lib/python3.8/site-packages (0.0.12)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.8/site-packages (from transformers==4.23.1) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.8/site-packages (from transformers==4.23.1) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/app-root/lib/python3.8/site-packages (from transformers==4.23.1) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /opt/app-root/lib/python3.8/site-packages (from transformers==4.23.1) (0.11.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.8/site-packages (from transformers==4.23.1) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/app-root/lib/python3.8/site-packages (from transformers==4.23.1) (4.64.0)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.8/site-packages (from transformers==4.23.1) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.8/site-packages (from transformers==4.23.1) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib/python3.8/site-packages (from transformers==4.23.1) (2022.3.15)\n",
      "Requirement already satisfied: responses<0.19 in /opt/app-root/lib/python3.8/site-packages (from datasets<=1.18.4) (0.18.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/app-root/lib/python3.8/site-packages (from datasets<=1.18.4) (2022.11.0)\n",
      "Requirement already satisfied: aiohttp in /opt/app-root/lib/python3.8/site-packages (from datasets<=1.18.4) (3.8.1)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib/python3.8/site-packages (from datasets<=1.18.4) (1.4.2)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/app-root/lib/python3.8/site-packages (from datasets<=1.18.4) (7.0.0)\n",
      "Requirement already satisfied: dill in /opt/app-root/lib/python3.8/site-packages (from datasets<=1.18.4) (0.3.6)\n",
      "Requirement already satisfied: multiprocess in /opt/app-root/lib/python3.8/site-packages (from datasets<=1.18.4) (0.70.14)\n",
      "Requirement already satisfied: xxhash in /opt/app-root/lib/python3.8/site-packages (from datasets<=1.18.4) (3.2.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/app-root/lib/python3.8/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /opt/app-root/lib/python3.8/site-packages (from seqeval) (2.8.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/app-root/lib/python3.8/site-packages (from aiohttp->datasets<=1.18.4) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib/python3.8/site-packages (from aiohttp->datasets<=1.18.4) (1.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/app-root/lib/python3.8/site-packages (from aiohttp->datasets<=1.18.4) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/app-root/lib/python3.8/site-packages (from aiohttp->datasets<=1.18.4) (2.0.12)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib/python3.8/site-packages (from aiohttp->datasets<=1.18.4) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib/python3.8/site-packages (from aiohttp->datasets<=1.18.4) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib/python3.8/site-packages (from aiohttp->datasets<=1.18.4) (21.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.23.1) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/app-root/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.23.1) (3.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.8/site-packages (from requests->transformers==4.23.1) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.8/site-packages (from requests->transformers==4.23.1) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/app-root/lib/python3.8/site-packages (from requests->transformers==4.23.1) (1.26.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib/python3.8/site-packages (from pandas->datasets<=1.18.4) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/app-root/lib/python3.8/site-packages (from pandas->datasets<=1.18.4) (2.8.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/app-root/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/app-root/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/app-root/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets<=1.18.4) (1.16.0)\n",
      "Installing collected packages: transformers, datasets\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.25.1\n",
      "    Uninstalling transformers-4.25.1:\n",
      "      Successfully uninstalled transformers-4.25.1\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.8.0\n",
      "    Uninstalling datasets-2.8.0:\n",
      "      Successfully uninstalled datasets-2.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "farm 0.5.0 requires transformers==3.3.1, but you have transformers 4.23.1 which is incompatible.\n",
      "2023-01-13 07:41:21 deepsparse.transformers INFO     deepsparse-transformers and dependencies successfully installed\n",
      "2023-01-13 07:41:21,805 [558] INFO     deepsparse.transformers: deepsparse-transformers and dependencies successfully installed\n",
      "2023-01-13 07:41:21 deepsparse.transformers WARNING  the neuralmagic fork of transformers may not be installed. it can be installed via `pip install https://github.com/neuralmagic/transformers/releases/download/nightly/transformers-4.23.1-py3-none-any.whl`\n",
      "2023-01-13 07:41:21,806 [558] WARNING  deepsparse.transformers: the neuralmagic fork of transformers may not be installed. it can be installed via `pip install https://github.com/neuralmagic/transformers/releases/download/nightly/transformers-4.23.1-py3-none-any.whl`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed datasets-1.18.4 transformers-4.23.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepSparse, Copyright 2021-present / Neuralmagic, Inc. version: 1.3.1 COMMUNITY | (d1a12439) (release) (optimized) (system=avx512, binary=avx512)\n",
      "[7fafabfff700 >WARN<  operator() ./src/include/wand/utility/warnings.hpp:14] Generating emulated code for quantized (INT8) operations since no VNNI instructions were detected. Set NM_FAST_VNNI_EMULATION=1 to increase performance at the expense of accuracy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/5, 04_NOVATEK_AR_2016_ENG_11\n",
      "loop : 0\n",
      "distilbert_mnli_pruned80\n",
      "363.48696660995483\n",
      "Processing 2/5, 04_NOVATEK_AR_2018_ENG_15\n",
      "loop : 1\n",
      "distilbert_mnli_pruned80\n",
      "344.98051285743713\n",
      "Processing 3/5, 2013_book_mol_ar_eng_fin\n",
      "loop : 2\n",
      "distilbert_mnli_pruned80\n",
      "939.6917035579681\n",
      "Processing 4/5, 2015_BASF_Report\n",
      "loop : 3\n",
      "distilbert_mnli_pruned80\n",
      "1141.9932181835175\n",
      "Processing 5/5, 2017 Sustainability Report\n",
      "loop : 4\n",
      "distilbert_mnli_pruned80\n",
      "325.9426770210266\n",
      "Processing 1/5, 04_NOVATEK_AR_2016_ENG_11\n",
      "loop : 0\n",
      "distilbert_qqp_pruned80\n",
      "382.77617383003235\n",
      "Processing 2/5, 04_NOVATEK_AR_2018_ENG_15\n",
      "loop : 1\n",
      "distilbert_qqp_pruned80\n",
      "364.8406844139099\n",
      "Processing 3/5, 2013_book_mol_ar_eng_fin\n",
      "loop : 2\n",
      "distilbert_qqp_pruned80\n",
      "992.151086807251\n",
      "Processing 4/5, 2015_BASF_Report\n",
      "loop : 3\n",
      "distilbert_qqp_pruned80\n",
      "1201.654770374298\n",
      "Processing 5/5, 2017 Sustainability Report\n",
      "loop : 4\n",
      "distilbert_qqp_pruned80\n",
      "345.39869475364685\n",
      "Processing 1/5, 04_NOVATEK_AR_2016_ENG_11\n",
      "loop : 0\n",
      "obert_mnli_pruned90\n",
      "438.9388129711151\n",
      "Processing 2/5, 04_NOVATEK_AR_2018_ENG_15\n",
      "loop : 1\n",
      "obert_mnli_pruned90\n",
      "419.04258275032043\n",
      "Processing 3/5, 2013_book_mol_ar_eng_fin\n",
      "loop : 2\n",
      "obert_mnli_pruned90\n",
      "1135.6947507858276\n",
      "Processing 4/5, 2015_BASF_Report\n",
      "loop : 3\n",
      "obert_mnli_pruned90\n",
      "1370.3356137275696\n",
      "Processing 5/5, 2017 Sustainability Report\n",
      "loop : 4\n",
      "obert_mnli_pruned90\n",
      "390.4085068702698\n"
     ]
    }
   ],
   "source": [
    "metric_list = []\n",
    "for local_model_path, model_name in zip(local_model_paths,model_names):\n",
    "    tc_pipeline = Pipeline.create(\n",
    "        task=\"text-classification\",\n",
    "        model_path=local_model_path\n",
    "    )\n",
    "    for i,(pdf_name,file_path) in enumerate(all_text_path_dict.items()):\n",
    "        print(f'Processing {i+1}/{len(all_text_path_dict)}, {pdf_name}')\n",
    "        print(model_name)\n",
    "        data = gather_data(pdf_name, file_path)\n",
    "        num_data_points = len(data)\n",
    "        num_pages = data[len(data)-1]['page']\n",
    "        chunk_size = 5000\n",
    "        chunk_idx = 0\n",
    "        total_file_time = 0\n",
    "        temp_df_list = list()\n",
    "        temp_df = pd.DataFrame(data).drop(['pdf_name', 'page'], axis=1)\n",
    "        temp_df_list = temp_df.values.tolist()\n",
    "        start = time.time()\n",
    "        inference = tc_pipeline(temp_df_list)\n",
    "        end = time.time()\n",
    "        total_file_time = (end - start)\n",
    "        print(total_file_time)\n",
    "        time_per_data_point = total_file_time / num_data_points\n",
    "        data_points_per_sec = 1/time_per_data_point\n",
    "        metric_list.append(\n",
    "            {'Model Name':model_name,\n",
    "             'PDF Name':pdf_name,\n",
    "             'Number of Pages':int(num_pages),\n",
    "             'Number of Data Points':num_data_points,\n",
    "             'Total Inference Time':total_file_time,\n",
    "             'Time per data point':time_per_data_point,\n",
    "             'Data points per sec':data_points_per_sec})\n",
    "    file_to_save = pd.DataFrame(metric_list)\n",
    "    file_to_save.to_csv(f\"file_to_save_cpu4{model_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26b575aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dfs = pd.DataFrame(metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39993a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Size(MB)</th>\n",
       "      <th>PDF Name</th>\n",
       "      <th>Number of Pages</th>\n",
       "      <th>Number of Data Points</th>\n",
       "      <th>Total Inference Time</th>\n",
       "      <th>Time per data point</th>\n",
       "      <th>Data points per sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert_mnli_pruned80</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>04_NOVATEK_AR_2016_ENG_11</td>\n",
       "      <td>119</td>\n",
       "      <td>24264</td>\n",
       "      <td>363.486967</td>\n",
       "      <td>0.014981</td>\n",
       "      <td>66.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>distilbert_mnli_pruned80</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>04_NOVATEK_AR_2018_ENG_15</td>\n",
       "      <td>105</td>\n",
       "      <td>23112</td>\n",
       "      <td>344.980513</td>\n",
       "      <td>0.014926</td>\n",
       "      <td>66.995089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distilbert_mnli_pruned80</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>2013_book_mol_ar_eng_fin</td>\n",
       "      <td>135</td>\n",
       "      <td>63024</td>\n",
       "      <td>939.691704</td>\n",
       "      <td>0.014910</td>\n",
       "      <td>67.068805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert_mnli_pruned80</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>2015_BASF_Report</td>\n",
       "      <td>261</td>\n",
       "      <td>76392</td>\n",
       "      <td>1141.993218</td>\n",
       "      <td>0.014949</td>\n",
       "      <td>66.893567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>distilbert_mnli_pruned80</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>2017 Sustainability Report</td>\n",
       "      <td>57</td>\n",
       "      <td>21936</td>\n",
       "      <td>325.942677</td>\n",
       "      <td>0.014859</td>\n",
       "      <td>67.300177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Name  Model Size(MB)                    PDF Name  \\\n",
       "0  distilbert_mnli_pruned80        0.004096   04_NOVATEK_AR_2016_ENG_11   \n",
       "1  distilbert_mnli_pruned80        0.004096   04_NOVATEK_AR_2018_ENG_15   \n",
       "2  distilbert_mnli_pruned80        0.004096    2013_book_mol_ar_eng_fin   \n",
       "3  distilbert_mnli_pruned80        0.004096            2015_BASF_Report   \n",
       "4  distilbert_mnli_pruned80        0.004096  2017 Sustainability Report   \n",
       "\n",
       "   Number of Pages  Number of Data Points  Total Inference Time  \\\n",
       "0              119                  24264            363.486967   \n",
       "1              105                  23112            344.980513   \n",
       "2              135                  63024            939.691704   \n",
       "3              261                  76392           1141.993218   \n",
       "4               57                  21936            325.942677   \n",
       "\n",
       "   Time per data point  Data points per sec  \n",
       "0             0.014981            66.753425  \n",
       "1             0.014926            66.995089  \n",
       "2             0.014910            67.068805  \n",
       "3             0.014949            66.893567  \n",
       "4             0.014859            67.300177  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23de10b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(\"file_to_save_cpu4obert_mnli_pruned90.csv\")\n",
    "df8 = pd.read_csv(\"file_to_save_cpu8obert_mnli_pruned90.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60376b7-78ff-4b38-a0bd-d3d3c6df91cf",
   "metadata": {},
   "source": [
    "**Model Name: distilbert_mnli_pruned80, Size: 438.02 MB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e94620d-a94c-4eff-af4b-76ebf199f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df14 = df4[df4['Model Name']=='distilbert_mnli_pruned80']\n",
    "df18 = df8[df8['Model Name']=='distilbert_mnli_pruned80']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30bc1762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     0.014925\n",
       "std      0.000045\n",
       "min      0.014859\n",
       "25%      0.014910\n",
       "50%      0.014926\n",
       "75%      0.014949\n",
       "max      0.014981\n",
       "Name: Time per data point, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average time per data point\n",
    "\n",
    "df14['Time per data point'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb5cb01",
   "metadata": {},
   "source": [
    "The average time per data point is 0.014925 seconds. A pdf with on average ~157 pages, and ~387 data points per page, will take 15 mins to execute for 4 CPU cores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55b99f8c-6e2d-49e2-913e-a7d9cdf42883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     0.007645\n",
       "std      0.000005\n",
       "min      0.007640\n",
       "25%      0.007643\n",
       "50%      0.007644\n",
       "75%      0.007647\n",
       "max      0.007653\n",
       "Name: Time per data point, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average time per data point\n",
    "\n",
    "df18['Time per data point'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a346c76-f9fd-42c2-a6f9-1e0e92927f4b",
   "metadata": {},
   "source": [
    "The average time per data point is 0.007645 seconds. A pdf with on average ~157 pages, and ~387 data points per page, will take 8 mins to execute, for 8 cores CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db31b48",
   "metadata": {},
   "source": [
    "**Model Name: distilbert_qqp_pruned80, Size: 438.02 MB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cebcb791-6439-4cee-b34f-7362774d9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24 = df4[df4['Model Name']=='distilbert_qqp_pruned80']\n",
    "df28 = df8[df8['Model Name']=='distilbert_qqp_pruned80']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "adc8e963-bb46-41f8-b3b7-9a114c348199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     0.015756\n",
       "std      0.000024\n",
       "min      0.015730\n",
       "25%      0.015742\n",
       "50%      0.015746\n",
       "75%      0.015775\n",
       "max      0.015786\n",
       "Name: Time per data point, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs# Average time per data point\n",
    "\n",
    "df24['Time per data point'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3865a92c-ad9e-4926-b0e6-7945756c08c6",
   "metadata": {},
   "source": [
    "The average time per data point is 0.0015756 seconds. A pdf with on average ~157 pages, and ~387 data points per page, will take 16 mins to execute, for 4 cores CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d7a441c-5390-4495-b353-f5fee0c052f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model Size(MB)</th>\n",
       "      <th>PDF Name</th>\n",
       "      <th>Number of Pages</th>\n",
       "      <th>Number of Data Points</th>\n",
       "      <th>Total Inference Time</th>\n",
       "      <th>Time per data point</th>\n",
       "      <th>Data points per sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>distilbert_qqp_pruned80</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>04_NOVATEK_AR_2016_ENG_11</td>\n",
       "      <td>119</td>\n",
       "      <td>24264</td>\n",
       "      <td>189.696231</td>\n",
       "      <td>0.007818</td>\n",
       "      <td>127.909764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>distilbert_qqp_pruned80</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>04_NOVATEK_AR_2018_ENG_15</td>\n",
       "      <td>105</td>\n",
       "      <td>23112</td>\n",
       "      <td>180.437520</td>\n",
       "      <td>0.007807</td>\n",
       "      <td>128.088659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>distilbert_qqp_pruned80</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>2013_book_mol_ar_eng_fin</td>\n",
       "      <td>135</td>\n",
       "      <td>63024</td>\n",
       "      <td>491.198755</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>128.306514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>distilbert_qqp_pruned80</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>2015_BASF_Report</td>\n",
       "      <td>261</td>\n",
       "      <td>76392</td>\n",
       "      <td>595.565105</td>\n",
       "      <td>0.007796</td>\n",
       "      <td>128.268093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>distilbert_qqp_pruned80</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>2017 Sustainability Report</td>\n",
       "      <td>57</td>\n",
       "      <td>21936</td>\n",
       "      <td>169.021273</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>129.782480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               Model Name  Model Size(MB)  \\\n",
       "5           5  distilbert_qqp_pruned80        0.004096   \n",
       "6           6  distilbert_qqp_pruned80        0.004096   \n",
       "7           7  distilbert_qqp_pruned80        0.004096   \n",
       "8           8  distilbert_qqp_pruned80        0.004096   \n",
       "9           9  distilbert_qqp_pruned80        0.004096   \n",
       "\n",
       "                     PDF Name  Number of Pages  Number of Data Points  \\\n",
       "5   04_NOVATEK_AR_2016_ENG_11              119                  24264   \n",
       "6   04_NOVATEK_AR_2018_ENG_15              105                  23112   \n",
       "7    2013_book_mol_ar_eng_fin              135                  63024   \n",
       "8            2015_BASF_Report              261                  76392   \n",
       "9  2017 Sustainability Report               57                  21936   \n",
       "\n",
       "   Total Inference Time  Time per data point  Data points per sec  \n",
       "5            189.696231             0.007818           127.909764  \n",
       "6            180.437520             0.007807           128.088659  \n",
       "7            491.198755             0.007794           128.306514  \n",
       "8            595.565105             0.007796           128.268093  \n",
       "9            169.021273             0.007705           129.782480  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "254c2447-637e-4139-8491-29abed043b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     0.007784\n",
       "std      0.000045\n",
       "min      0.007705\n",
       "25%      0.007794\n",
       "50%      0.007796\n",
       "75%      0.007807\n",
       "max      0.007818\n",
       "Name: Time per data point, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average time per data point\n",
    "\n",
    "df28['Time per data point'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd310f72-6953-431a-8368-0110249f0aba",
   "metadata": {},
   "source": [
    "The average time per data point is 0.00784 seconds. A pdf with on average ~157 pages, and ~387 data points per page, will take 8 mins to execute, for 8 cores CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4010f3-2d65-4292-a41f-33ad82f2235b",
   "metadata": {},
   "source": [
    "**Model Name: distilbert_qqp_pruned80, Size: 438.02 MB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1dcc1bc7-e1eb-4553-b3e6-8a5475986605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df34 = df4[df4['Model Name']=='obert_mnli_pruned90']\n",
    "df38 = df8[df8['Model Name']=='obert_mnli_pruned90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "956604ae-5d71-4db1-9cab-d599a0ddfc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     0.017995\n",
       "std      0.000133\n",
       "min      0.017798\n",
       "25%      0.017938\n",
       "50%      0.018020\n",
       "75%      0.018090\n",
       "max      0.018131\n",
       "Name: Time per data point, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average time per data point\n",
    "\n",
    "df34['Time per data point'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1de709-0239-4807-bf59-e547ee1face8",
   "metadata": {},
   "source": [
    "The average time per data point is 0.017995 seconds. A pdf with on average ~157 pages, and ~387 data points per page, will take 18 mins to execute, for 4 cores CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e9b74fd3-81a3-41c1-801e-b44121c6cf32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     0.008859\n",
       "std      0.000017\n",
       "min      0.008844\n",
       "25%      0.008847\n",
       "50%      0.008851\n",
       "75%      0.008871\n",
       "max      0.008883\n",
       "Name: Time per data point, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average time per data point\n",
    "\n",
    "df38['Time per data point'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8c8fae-d139-457d-b3ed-abeb4086cbdf",
   "metadata": {},
   "source": [
    "The average time per data point is 0.008859 seconds. A pdf with on average ~157 pages, and ~387 data points per page, will take 9 mins to execute, for 8 cores CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d919a5-efeb-4f23-b894-c7284d15449d",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab954c8-a571-447b-8bb1-4d6251dd7b37",
   "metadata": {},
   "source": [
    "Based on our experiments, we can conclude that DeepSparse, in combination with SparseZoo, is an efficient and effective framework for optimizing and executing sparse deep learning models on the CPU. In this notebook, we focused on calculating the inference time for three pre-trained models: \"distilbert_mnli_pruned80\", \"distilbert_qqp_pruned80\", and \"obert_mnli_pruned90\". By running our experiments on both 4 and 8 cores of the CPU, we were able to assess the impact of the number of cores on the inference time.\n",
    "\n",
    "Our results showed that the inference time decreased as we increased the number of CPU cores, which is expected. Although we observed some variation in the inference times of the different models, overall, the results were comparable. These findings provide valuable insights into the performance of sparse models on general-purpose hardware and can help guide the development of future models and frameworks.\n",
    "\n",
    "Overall, our experiments demonstrated the usefulness of SparseZoo and DeepSparse for working with sparse models and provided a glimpse into the potential of these technologies for optimizing deep learning workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
