{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3fa2905-def8-45b5-aca9-aa39a9882230",
   "metadata": {},
   "source": [
    "# Teacher and Student Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ee71a-a1dd-4589-ab9b-56520a8c44dd",
   "metadata": {},
   "source": [
    "Custom knowledge distillation is a technique in deep learning that involves training a smaller, simpler model (the \"student\") to mimic the behavior of a larger, more complex model (the \"teacher\"). This process is intended to improve the efficiency of deep learning models, by compressing the knowledge of the larger model into a smaller one, without sacrificing too much accuracy. In this notebook, we explore the capabilities of custom knowledge distillation teacher-student models by training them and evaluating their F1 score.\n",
    "\n",
    "Specifically, we are training a custom knowledge distillation teacher-student model and evaluating its F1 score. The pre-trained teacher model is 'bert-base-uncased' and the student model is a smaller, pruned version of 'bert-base-uncased'. By using custom knowledge distillation, we aim to improve the efficiency of the student model, without sacrificing its accuracy.\n",
    "\n",
    "In this notebook, we will be using PyTorch to implement the custom knowledge distillation process and train the student model. We will then evaluate the performance of the student model by calculating its F1 score. By exploring the performance of custom knowledge distillation teacher-student models, we hope to contribute to the ongoing research and development of efficient and effective deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a89a2fdc-57fe-4966-9831-0008e3f8bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "from src.data.s3_communication import S3Communication\n",
    "import config\n",
    "from torch import cuda\n",
    "import transformers\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from deepsparse import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('always')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f08434e1-dab3-4f21-8bf0-8fb5370cd940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv_dir = os.environ.get(\n",
    "    \"CREDENTIAL_DOTENV_DIR\", os.environ.get(\"PWD\", \"/opt/app-root/src\")\n",
    ")\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / \"credentials.env\"\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7494b6b3-29eb-4342-92dc-2b2c89cab2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init s3 connector\n",
    "s3c = S3Communication(\n",
    "    s3_endpoint_url=os.getenv(\"S3_ENDPOINT\"),\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    s3_bucket=os.getenv(\"S3_BUCKET\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a8b5b-7c5a-4090-9868-5cf2270dfa9c",
   "metadata": {},
   "source": [
    "# Process dataset for sparseml training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55ecac39-186a-49b8-8ae4-3bef17d69079",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3c.download_files_in_prefix_to_dir(\n",
    "    config.BASE_TRAIN_TEST_DATASET_S3_PREFIX,\n",
    "    config.BASE_PROCESSED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7762d1cb-a7e2-486e-b6e1-a084486b0b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3c.download_files_in_prefix_to_dir(\n",
    "    config.BASE_TRAIN_TEST_DATASET_S3_PREFIX,\n",
    "    config.BASE_PROCESSED_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a7e630a-d31e-40cc-afb3-4b2f14091dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = str(config.BASE_PROCESSED_DATA)+'/rel_test_split.csv'\n",
    "test_data = pd.read_csv(test_data_path, index_col=0)\n",
    "test_data.rename(columns={'text': 'question', 'text_b':'sentence'}, inplace=True)\n",
    "\n",
    "train_data_path = str(config.BASE_PROCESSED_DATA)+'/rel_train_split.csv'\n",
    "train_data = pd.read_csv(train_data_path, index_col=0)\n",
    "train_data.rename(columns={'text': 'question', 'text_b':'sentence'}, inplace=True)\n",
    "\n",
    "train_data.to_csv(train_data_path)\n",
    "test_data.to_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "26595653-65ba-4567-be4d-d38d3b9f0580",
   "metadata": {},
   "outputs": [],
   "source": [
    "trds = Dataset.from_pandas(train_data)\n",
    "teds = Dataset.from_pandas(test_data.drop('label', axis=1))\n",
    "\n",
    "climate_dataset = DatasetDict()\n",
    "\n",
    "climate_dataset['train'] = trds\n",
    "climate_dataset['test'] = teds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30188fa9-fe18-4131-b45a-d6f982ef9994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'question', 'sentence', '__index_level_0__'],\n",
       "        num_rows: 2033\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'sentence', '__index_level_0__'],\n",
       "        num_rows: 509\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9ef46c-72cb-4a25-8b80-131d2344cb4b",
   "metadata": {},
   "source": [
    "# Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf92494-8e4b-46e4-aadf-ccf099a2915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sparseml.transformers.text_classification --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "195d11ae-6734-4410-9e31-54e00e6f68ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n!sparseml.transformers.text_classification --model_name_or_path bert-base-uncased --train_file '/opt/app-root/src/data/processed/rel_train_split.csv' --validation_file '/opt/app-root/src/data/processed/rel_test_split.csv' --label_column_name 'label' --input_column_name 'question,sentence' --do_train --do_eval --evaluation_strategy epoch --per_device_train_batch_size 32 --learning_rate 5e-5 --max_seq_length 128 --output_dir models/teacher --num_train_epochs 8 --metric_for_best_model 'f1' --overwrite_output_dir --seed 2021 \\n# For deepsparse\\n!sparseml.transformers.export_onnx --model_path models/teacher/ --task 'text-classification' \""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!sparseml.transformers.text_classification \\\n",
    "--model_name_or_path bert-base-uncased \\  # noqa: E999\n",
    "--train_file '/opt/app-root/src/data/processed/rel_train_split.csv' \\\n",
    "--validation_file '/opt/app-root/src/data/processed/rel_test_split.csv' \\\n",
    "--label_column_name 'label' \\\n",
    "--input_column_name 'question,sentence' \\\n",
    "--do_train --do_eval --evaluation_strategy epoch \\\n",
    "--per_device_train_batch_size 32 \\\n",
    "--learning_rate 5e-5 \\\n",
    "--max_seq_length 128 \\\n",
    "--output_dir models/teacher \\\n",
    "--num_train_epochs 8 \\\n",
    "--metric_for_best_model 'f1' \\\n",
    "--overwrite_output_dir \\\n",
    "--seed 2021 \\\n",
    "\n",
    "# For deepsparse\n",
    "!sparseml.transformers.export_onnx \\\n",
    "--model_path models/teacher/ \\\n",
    "--task 'text-classification' \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516e6597-6fa7-4892-8dde-837eee530bdb",
   "metadata": {},
   "source": [
    "# Sparse Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "602cf7db-2052-4fb8-be2b-1b69eebdc1e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n!sparseml.transformers.train.text_classification --model_name_or_path 'zoo:nlp/masked_language_modeling/bert-base/pytorch/huggingface/bookcorpus_wikitext/12layer_pruned80-none' --distill_teacher models/teacher --train_file '/opt/app-root/src/data/processed/rel_train_split.csv' --validation_file '/opt/app-root/src/data/processed/rel_test_split.csv' --label_column_name 'label' --input_column_name 'question,sentence' --do_train --do_eval --evaluation_strategy epoch --per_device_train_batch_size 16 --learning_rate 5e-4 --warmup_steps 11000 --output_dir models/12layer_pruned80-none --seed 11712 --num_train_epochs 50 --save_strategy epoch --save_total_limit 1 --metric_for_best_model 'f1' --overwrite_output_dir --recipe zoo:nlp/masked_language_modeling/bert-base/pytorch/huggingface/bookcorpus_wikitext/12layer_pruned80-none?recipe_type=transfer-MNLI\\n\\n# For deepsparse\\n!sparseml.transformers.export_onnx --model_path models/12layer_pruned80-none/ --task 'text-classification'\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "!sparseml.transformers.train.text_classification \\\n",
    "--model_name_or_path 'zoo:nlp/masked_language_modeling/bert-base/pytorch/huggingface/bookcorpus_wikitext/12layer_pruned80-none' \\\n",
    "--distill_teacher models/teacher \\\n",
    "--train_file '/opt/app-root/src/data/processed/rel_train_split.csv' \\\n",
    "--validation_file '/opt/app-root/src/data/processed/rel_test_split.csv' \\\n",
    "--label_column_name 'label' \\\n",
    "--input_column_name 'question,sentence' \\\n",
    "--do_train --do_eval --evaluation_strategy epoch \\\n",
    "--per_device_train_batch_size 16 \\\n",
    "--learning_rate 5e-4 \\\n",
    "--warmup_steps 11000 \\\n",
    "--output_dir models/12layer_pruned80-none \\\n",
    "--seed 11712 \\\n",
    "--num_train_epochs 50 \\\n",
    "--save_strategy epoch \\\n",
    "--save_total_limit 1 \\\n",
    "--metric_for_best_model 'f1' \\\n",
    "--overwrite_output_dir \\\n",
    "--recipe zoo:nlp/masked_language_modeling/bert-base/pytorch/huggingface/bookcorpus_wikitext/12layer_pruned80-none?recipe_type=transfer-MNLI\n",
    "\n",
    "# For deepsparse\n",
    "!sparseml.transformers.export_onnx \\\n",
    "--model_path models/12layer_pruned80-none/ \\\n",
    "--task 'text-classification' \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a733f2f-0a30-4f67-a1c9-aa8039a81be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trds = Dataset.from_pandas(train_data)\n",
    "teds = Dataset.from_pandas(test_data.drop('label', axis=1))\n",
    "\n",
    "climate_dataset = DatasetDict()\n",
    "\n",
    "climate_dataset['train'] = trds\n",
    "climate_dataset['test'] = teds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b967d73f-74a9-4c5d-a799-8a11dab6e8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_batches(data_df, tokenizer, batch_size=32):\n",
    "    encoded_dataset = list()\n",
    "    batch = list()\n",
    "    for df, row in data_df.iterrows():\n",
    "        if len(batch) < batch_size:\n",
    "            batch.append([row['question'], row['sentence']])\n",
    "        else:\n",
    "            encoded_dataset.append(tokenizer(batch,\n",
    "                                             truncation=True,\n",
    "                                             return_tensors='pt',\n",
    "                                             padding=True))\n",
    "            batch = [[row['question'], row['sentence']]]\n",
    "\n",
    "    if batch:\n",
    "        encoded_dataset.append(tokenizer(batch,\n",
    "                                         truncation=True,\n",
    "                                         return_tensors='pt',\n",
    "                                         padding=True))\n",
    "    return encoded_dataset\n",
    "\n",
    "def predict(encoded_dataset, model):\n",
    "    outputs = list()\n",
    "    for batch in encoded_dataset:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            outputs.extend(outs.logits.argmax(axis=1).tolist())\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def get_model_f1score(model_path, test_data):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)\n",
    "    \n",
    "    encoded_dataset = create_batches(test_data, tokenizer)\n",
    "    test_data[\"pred\"] = predict(encoded_dataset, model)\n",
    "    \n",
    "    groups = test_data.groupby(\"question\")\n",
    "    scores = {}\n",
    "    for group, data in groups:\n",
    "        pred = data.pred\n",
    "        true = data.label\n",
    "        scores[group] = {}\n",
    "        scores[group][\"accuracy\"] = accuracy_score(true, pred)\n",
    "        scores[group][\"f1_score\"] = f1_score(true, pred)\n",
    "        scores[group][\"recall_score\"] = recall_score(true, pred)\n",
    "        scores[group][\"precision_score\"] = precision_score(true, pred)\n",
    "        scores[group][\"support\"] = len(pred)\n",
    "\n",
    "    # kpi wise performance metrics\n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    return scores_df.loc['f1_score'].mean()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60319d70-f9e8-47ef-bd44-8a43788119d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 13:21:19,994 [629] WARNING  py.warnings: /opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "\n",
      "2023-02-17 13:21:19,997 [629] WARNING  py.warnings: /opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "2023-02-17 13:21:19,999 [629] WARNING  py.warnings: /opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9124404257977322"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_f1score('models/teacher/',test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8fc9b77-4b26-4db3-8b20-947e37fbd376",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 13:21:28,144 [629] WARNING  py.warnings: /opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "\n",
      "2023-02-17 13:21:28,146 [629] WARNING  py.warnings: /opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "2023-02-17 13:21:28,149 [629] WARNING  py.warnings: /opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8691582632415494"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_f1score('models/12layer_pruned80-none/',test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "297b3c20-9a4f-40a5-a9bd-eb38e9dfe40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 13:21:34,330 [629] WARNING  py.warnings: /opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "\n",
      "2023-02-17 13:21:34,332 [629] WARNING  py.warnings: /opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "2023-02-17 13:21:34,334 [629] WARNING  py.warnings: /opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8650101491961957"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_f1score('models/12layer_pruned90-none/',test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db87478b-e0fd-4482-83a6-c42628ae05e3",
   "metadata": {},
   "source": [
    "# Saving Models to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cac9913-3217-43c5-91cb-07801def65de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(local_path, model_name):\n",
    "    #trainer.save_model(local_path)\n",
    "    #shutil.make_archive(local_path, 'zip', local_path)\n",
    "    buffer = BytesIO()\n",
    "    with zipfile.ZipFile(buffer, 'a') as z:\n",
    "        for dirname, _, files in os.walk(local_path):\n",
    "            for f in files:\n",
    "                f_path = os.path.join(dirname, f)\n",
    "                with open (f_path, 'rb') as file_content:\n",
    "                    z.writestr(f\"{model_name}/{f}\", file_content.read())\n",
    "    buffer.seek(0)\n",
    "    # upload model to s3\n",
    "    s3c._upload_bytes(\n",
    "        buffer_bytes=buffer,\n",
    "        prefix=config.BASE_SAVED_MODELS_S3_PREFIX,\n",
    "        key=f\"{model_name}.zip\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "199a2275-eb10-41d8-98de-75191c09aa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 13:22:43,585 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'teacher/config.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:22:43,587 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'teacher/tokenizer_config.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:22:43,591 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'teacher/tokenizer.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:22:46,456 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'teacher/config.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:22:46,458 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'teacher/tokenizer_config.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:22:46,463 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'teacher/vocab.txt'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:22:46,464 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'teacher/scheduler.pt'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:22:46,466 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'teacher/training_args.bin'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:22:46,468 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'teacher/trainer_state.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:22:46,472 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'teacher/tokenizer.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:22:48,994 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'teacher/pytorch_model.bin'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:22:55,385 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'teacher/optimizer.pt'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:22:56,719 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: 'teacher/special_tokens_map.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:23:55,171 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/config.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:23:55,173 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/tokenizer_config.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:23:55,177 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/tokenizer.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:23:58,030 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/config.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:23:58,032 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/tokenizer_config.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:23:58,034 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/recipe.yaml'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:23:58,037 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/vocab.txt'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:23:58,039 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/scheduler.pt'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:23:58,041 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/training_args.bin'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:23:58,042 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/trainer_state.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:23:58,046 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/tokenizer.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:00,578 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/pytorch_model.bin'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:06,969 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/optimizer.pt'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:08,315 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned80-none/special_tokens_map.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:30,699 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/config.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:30,700 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/tokenizer_config.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:30,702 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/tokenizer.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:31,602 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/config.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:31,603 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/tokenizer_config.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:31,604 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/recipe.yaml'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:31,606 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/vocab.txt'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:31,607 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/scheduler.pt'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:31,608 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/training_args.bin'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:31,609 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/trainer_state.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:31,611 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/tokenizer.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:31,863 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/pytorch_model.bin'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:33,012 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/optimizer.pt'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n",
      "2023-02-17 13:24:34,332 [629] WARNING  py.warnings: /usr/lib64/python3.8/zipfile.py:1517: UserWarning: Duplicate name: '12layer_pruned90-none/special_tokens_map.json'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_model('models/teacher','teacher')\n",
    "save_model('models/12layer_pruned80-none','12layer_pruned80-none')\n",
    "save_model('models/12layer_pruned80-none','12layer_pruned90-none')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef93ae7b-d88e-4a10-acfa-faad77a7dff2",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba1861d2-595f-4c1d-95ab-fa9a2326be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_table = {'model_name':['12layer_pruned90-none',\n",
    "                          '12layer_pruned80-none',\n",
    "                          'teacher'],\n",
    "            'Recipe_used':['zoo:nlp/masked_language_modeling/bert-base/pytorch/huggingface/bookcorpus_wikitext/12layer_pruned90-none?recipe_type=transfer-MNLI',\n",
    "                           'zoo:nlp/masked_language_modeling/bert-base/pytorch/huggingface/bookcorpus_wikitext/12layer_pruned80-none?recipe_type=transfer-MNLI',\n",
    "                           ''],\n",
    "            'Size (MB)':[os.path.getsize('models/12layer_pruned90-none/pytorch_model.bin')/1000000,\n",
    "                         os.path.getsize('models/12layer_pruned80-none/pytorch_model.bin')/1000000,\n",
    "                         os.path.getsize('models/teacher/pytorch_model.bin')/1000000],             \n",
    "            'F1-Score':[0.86, 0.86, 0.91]}\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4996946-0499-4147-8439-30c97fa7be5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>Recipe_used</th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12layer_pruned90-none</td>\n",
       "      <td>zoo:nlp/masked_language_modeling/bert-base/pyt...</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12layer_pruned80-none</td>\n",
       "      <td>zoo:nlp/masked_language_modeling/bert-base/pyt...</td>\n",
       "      <td>438.011337</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teacher</td>\n",
       "      <td></td>\n",
       "      <td>438.011337</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_name                                        Recipe_used  \\\n",
       "0  12layer_pruned90-none  zoo:nlp/masked_language_modeling/bert-base/pyt...   \n",
       "1  12layer_pruned80-none  zoo:nlp/masked_language_modeling/bert-base/pyt...   \n",
       "2                teacher                                                      \n",
       "\n",
       "    Size (MB)  F1-Score  \n",
       "0  438.011337      0.86  \n",
       "1  438.011337      0.86  \n",
       "2  438.011337      0.91  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(F1_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbfea2a-8ee0-4245-9c43-e17dcabbc238",
   "metadata": {},
   "source": [
    "In conclusion, our evaluation of three custom knowledge distillation models - '12layer_pruned90-none', '12layer_pruned80-none', and 'teacher' - has yielded some interesting results. Despite the similar F1-Scores achieved by '12layer_pruned90-none' and '12layer_pruned80-none' (0.86), they had the same recipe and similar size, suggesting that pruning did not significantly affect their size or performance. The 'teacher' model, on the other hand, achieved a higher F1-Score (0.91).\n",
    "\n",
    "These results highlight the potential of custom knowledge distillation for improving the efficiency of deep learning models, even in cases where pruning may not result in significant size reductions or performance improvements. Additionally, the findings contribute to the ongoing research and development of custom knowledge distillation models and their applications in various domains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
